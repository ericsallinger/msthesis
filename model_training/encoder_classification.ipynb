{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Human activity classification with convolutional encoder feature representations\n",
    "\n",
    "The model architecture and feature engineering methods from the following paper are implemented\n",
    "\n",
    "[On the Role of Features in HAR](https://dl.acm.org/doi/10.1145/3341163.3347727)\n",
    "\n",
    "Classification: probabilistic classification with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR\n",
    "\n",
    "\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "module_dir = \"../modules\"\n",
    "if module_dir not in sys.path:\n",
    "    sys.path.append(module_dir)\n",
    "    \n",
    "from frame_dataloader_heavy import WorkloadFrame\n",
    "from convolutional_autoencoder import ConvAE\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cognitive/Physical workload Dataset\n",
    "\n",
    "Input: consists of individual frames of length context_length * signal_length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification head\n",
    "\n",
    "Train classification head on encoded feature representations, backpropagate through encoder aswell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model name': 'conv_ae_6253059', 'learning rate': 0.001, 'optimizer': 'Adam', 'latent dim': 2084, 'channel sizes': [1, 64, 128, 256, 512], 'kernel size': [3, 3]}\n"
     ]
    }
   ],
   "source": [
    "with open(model_filepath+model_name+'.json', 'r') as file:\n",
    "    meta_data = json.load(file)\n",
    "print(meta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained conv_ae\n",
    "\n",
    "conv_ae_2 = ConvAE2d()\n",
    "conv_ae_2.load_state_dict(torch.load('path_to_model/conv_ae.pth'))\n",
    "conv_ae_2.eval()\n",
    "\n",
    "# freeze all layers\n",
    "for param in conv_ae.parameters():\n",
    "    param.requires_grad = False  \n",
    "\n",
    "# change last fc layers\n",
    "num_features = conv_ae_2.fc.in_features\n",
    "conv_ae_2.fc = nn.Linear(num_features, new_num_classes)\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "conv_ae_2.to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = torch.optim.Adam(conv_ae_2.fc.parameters(), lr=1e-3)  # only train last layer\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification model parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
